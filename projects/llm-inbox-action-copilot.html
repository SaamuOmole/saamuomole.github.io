<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>LLM Inbox Action Copilot - Samuel Omole</title>
    <link rel="stylesheet" href="../style.css" />
  </head>
  <body>
    <a href="../index.html">← Back to home</a>
    <h1>LLM Inbox Action Copilot</h1>
    <p>
      <strong>Focus</strong>: Local-first email triage using LLM pipelines,
      retrieval, and supervised ML to detect intent and required action.
    </p>

    <p>
      Built an end-to-end email triage system that analyzes real inbox data to
      determine whether a message requires action and classify the type of
      action (meetings, invoices, replies, tasks, etc.).
    </p>
    <p>
      The project goes beyond prompt engineering to explore how system
      architecture, retrieval, and supervised learning affect reliability. It
      demonstrates the limits of prompt-only LLM classification and shows when
      lightweight supervised models outperform larger generative models for
      structured tasks.
    </p>

    <h2>What I Did</h2>
    <ul>
      <li>
        Parsed real .eml email files exported from my inbox using Thunderbird
      </li>

      <li>
        Built a robust HTML-to-text cleaning pipeline with reply stripping
      </li>
      <li>
        Designed a weak-labeling system using heuristic rules to bootstrap
        intent and action labels
      </li>
      <li>
        Created a custom Streamlit labeling UI to manually annotate a gold
        dataset, representing the ground truth to evaluate against
      </li>
      <li>
        Defined intent categories based on user workflow, not just email content
      </li>

      <h3>LLM & Architecture Exploration (v1-v6)</h3>
      <li>
        Implemented local LLM inference using Ollama with strict JSON outputs
      </li>
      <li>Benchmarked against OpenAI API models</li>
      <li>Evaluated multiple LLM architectures including:</li>
      <ul>
        <li>Single-stage classification</li>
        <li>Stricter prompt-based decision rules</li>
        <li>Two-stage pipelines (action detection → intent classification)</li>
        <li>Confidence-gated routing to balance precision and recall</li>
        <li>
          Retrieval-Augmented variants (RAG over historical emails and labelled
          examples)
        </li>
      </ul>
      <li>
        Conducted structured error analysis using confusion matrices and
        precision/recall metrics
      </li>
      <h3>Supervised Baseline (v7 - Final Model)</h3>
      <li>Generated semantic embeddings using sentence-transformers</li>
      <li>Trained logistic regression classifiers</li>
      <li>
        Applied 5-fold out-of-fold cross-validation to prevent data leakage
      </li>
      <li>Compared supervised results directly against LLM pipelines</li>
    </ul>

    <h2>Model Performance (v7: Embedding + Logistic Regression)</h2>

    <p>
      <img
        class="figure"
        src="../assets/images/intent_confusion_matrix_v7.png"
        alt="Intent Confusion Matrix"
        loading="lazy"
        style="width: 70%; display: block; margin: 0 auto"
      />
    </p>
    <p class="figure-caption">Confusion matrix of predicted LLM intents - v7</p>

    <br />

    <p class="table-caption">Performance comparison for final model - v7</p>

    <div class="metrics-table">
      <table>
        <thead>
          <tr>
            <th>Metric</th>
            <th>v7 (Embedding + LR)</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>Intent Accuracy</td>
            <td>0.665</td>
          </tr>
          <tr>
            <td>Action Accuracy</td>
            <td>0.790</td>
          </tr>
          <tr>
            <td>Action Precision</td>
            <td>0.704</td>
          </tr>
          <tr class="best">
            <td>Action Recall</td>
            <td>0.841</td>
          </tr>
          <tr>
            <td>Action F1</td>
            <td>0.767</td>
          </tr>
        </tbody>
      </table>
    </div>

    <h2>Outputs</h2>
    <ul>
      <li>Cleaned, structured dataset derived from real inbox emails</li>
      <li>Weakly labelled dataset used for sampling and exploration</li>
      <li>
        Gold-labelled dataset created via a custom Streamlit annotation
        interface
      </li>
      <li>LLM triage pipeline (multiple architectural variants)</li>
      <li>RAG inference framework</li>
      <li>Supervised embedding-based classifier (best-performing model)</li>
      <li>
        Reproducible evaluation and experimentation framework with quantitative
        benchmarking
      </li>
    </ul>

    <h2>Key Findings</h2>
    <ul>
      <li>
        Action detection is easier than fine-grained intent classification
        (classifying intent is harder due to workflow ambiguity)
      </li>
      <li>
        Prompt tuning alone has diminishing returns for intent classification
      </li>
      <li>
        Architectural design matters more than model size once baseline
        competence is achieved
      </li>
      <li>
        For structured multi-class classification, a supervised embedding-based
        model significantly outperformed prompt-engineered LLM pipelines
      </li>
    </ul>

    <p>
      The project is available and fully documented in this repository:
      <a href="https://github.com/SaamuOmole/llm-inbox-action-copilot"
        >Code (GitHub)</a
      >
    </p>
  </body>
</html>
